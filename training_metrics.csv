# Training configuration
# Layer Sizes: 784-128-128-128-128-10
# Base Learning Rate: 0.01000
# Decay Rate: 0.98000

Epoch,Accuracy,Loss
1,92.4300,0.251713
2,96.4533,0.122196
3,97.2317,0.091278
4,97.8017,0.070509
5,98.1433,0.059213
6,98.5983,0.045977
7,98.7533,0.039799
8,98.9333,0.034903
9,99.0350,0.030803
10,99.1767,0.025176
11,99.2700,0.022652
12,99.4150,0.018058
13,99.4767,0.016374
14,99.4950,0.015545
15,99.6483,0.012217
