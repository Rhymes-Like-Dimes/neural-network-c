# Training configuration
# Layer Sizes: 784-128-128-10
# Base Learning Rate: 0.01000
# Decay Rate: 0.98000

Epoch,Accuracy,Loss
1,93.2350,0.218560
2,96.7833,0.104699
3,97.6817,0.076349
4,98.0783,0.058462
5,98.5733,0.044951
6,98.8433,0.035709
7,99.0700,0.029750
8,99.1833,0.025206
9,99.3633,0.018854
10,99.5117,0.014744
11,99.5983,0.012332
12,99.6883,0.009486
13,99.8317,0.005184
14,99.9167,0.003262
15,99.9767,0.001211
